{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jpw306/Music-Genre-RNN/blob/main/Music_Genre_RNN_with_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "CTZ7TANRmHhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "jpuIApmAmAxw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse Music Data"
      ],
      "metadata": {
        "id": "qgOo8U17mNlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import CSV File\n",
        "df = pd.read_csv(\"train_data.csv\")\n",
        "\n",
        "# Seperate columns into features\n",
        "chroma_mean = df[\"chroma_stft_mean\"].to_numpy()\n",
        "chroma_var = df[\"chroma_stft_var\"].to_numpy()\n",
        "rms_mean = df[\"rms_mean\"].to_numpy()\n",
        "rms_var = df[\"rms_var\"].to_numpy()\n",
        "scm = df[\"spectral_centroid_mean\"].to_numpy()\n",
        "scv = df[\"spectral_centroid_var\"].to_numpy()\n",
        "sbm = df[\"spectral_bandwidth_mean\"].to_numpy()\n",
        "sbv = df[\"spectral_bandwidth_var\"].to_numpy()\n",
        "\n",
        "# Convert label from string to int\n",
        "map = {}\n",
        "y = []\n",
        "for label in df['label']:\n",
        "  if label not in map:\n",
        "    map.update({label: len(map)})\n",
        "  y.append(map.get(label))"
      ],
      "metadata": {
        "id": "vVQN5MZ3mP7r"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Music Data"
      ],
      "metadata": {
        "id": "zu_IFWw4mZQ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [chroma_mean, chroma_var, rms_mean, rms_var, scm, scv, sbm, sbv]\n",
        "\n",
        "# normalize between -1 and 1\n",
        "def normalize_range(arr):\n",
        "  arr_min = arr.min()\n",
        "  arr_max = arr.max()\n",
        "  for i in range(len(arr)):\n",
        "    arr[i] = (2 * (arr[i] - arr_min) / (arr_max - arr_min)) -1\n",
        "\n",
        "# normalize all data\n",
        "for x in features:\n",
        "  normalize_range(x)"
      ],
      "metadata": {
        "id": "pKjtKpIxmZ9L"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Constants"
      ],
      "metadata": {
        "id": "mgGQSZXbrSC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 8 # number of features\n",
        "output_size = len(df[\"label\"].unique()) # number of genres to detect (subject to change)\n",
        "hidden_size = math.floor(input_size * 2 / 3) + output_size # (2/3 input size) + output size"
      ],
      "metadata": {
        "id": "0qGUrNp-rThr"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some Functions"
      ],
      "metadata": {
        "id": "F9Av0tJf3IJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Given an index of test data, return all features for that sample\n",
        "\"\"\"\n",
        "def get_features(sample_index):\n",
        "  return_arr = [x[sample_index] for x in features]\n",
        "  return np.array(return_arr).reshape(input_size, 1).T"
      ],
      "metadata": {
        "id": "-ql2UNj83NOu"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up RNN / LSTM"
      ],
      "metadata": {
        "id": "LJUTQaJHmbve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"WEIGHTS:\"\"\"\n",
        "\n",
        "# calculate range for weights\n",
        "# using xavier initialization\n",
        "lower_x, upper_x = -1 / math.sqrt(input_size), 1 / math.sqrt(input_size) # input range for x_t\n",
        "lower_h, upper_h = -1 / math.sqrt(hidden_size), 1 / math.sqrt(hidden_size) # input range for h_t-1\n",
        "\n",
        "# function for h_size feedback neurons\n",
        "def h_size_feedback():\n",
        "  return np.random.uniform(lower_h, upper_h, (hidden_size, hidden_size))\n",
        "\n",
        "def x_size_feedback():\n",
        "  return np.random.uniform(lower_x, upper_x, (input_size, hidden_size))\n",
        "\n",
        "# notation: (W)eight_(t)o(f)rom\n",
        "W_fh = h_size_feedback() # weight into forget gate from h_t-1\n",
        "W_fx = x_size_feedback() # weight into forget gate from x_t (current input)\n",
        "W_ih = h_size_feedback() # weight into input gate from h_t-1 (For input gate)\n",
        "W_ix = x_size_feedback() # weight into input gate from x_t (For input gate)\n",
        "W_ch = h_size_feedback() # weight into input gate from h_t-1 (For candidate memory)\n",
        "W_cx = x_size_feedback() # weight into input gate from x_t (For candidate memory)\n",
        "W_oh = h_size_feedback() # weight into output gate from h_t-1\n",
        "W_ox = x_size_feedback() # weight into output gate from x_t\n",
        "\n",
        "weights = [W_fh, W_fx, W_ih, W_ix, W_ch, W_cx, W_oh, W_ox]\n",
        "\n",
        "\"\"\"BIASES:\"\"\"\n",
        "\n",
        "# notation: (B)ias_(t)o\n",
        "b_f = np.ones([hidden_size, 1]) # bias for forget gate\n",
        "b_i = np.ones([hidden_size, 1]) # bias for input gate\n",
        "b_c = np.ones([hidden_size, 1]) # bias for candidate memory\n",
        "b_o = np.ones([hidden_size, 1]) # bias for output gate\n",
        "\n",
        "biases = [b_f, b_i, b_c, b_o]"
      ],
      "metadata": {
        "id": "ogPgzl0AmgVP"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Common Functions"
      ],
      "metadata": {
        "id": "HOuasKuEwtmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\"\"\" BUILT IN NUMPY FUNCTIONS TO USE \"\"\"\n",
        "# np.add() for element wise addition\n",
        "# np.tanh() for tanh\n",
        "# np.multiply for element-wise multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ubUtj81ZwwFp",
        "outputId": "1d89e702-53e8-4a57-8181-3e635721dfb4"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' BUILT IN NUMPY FUNCTIONS TO USE '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Cell"
      ],
      "metadata": {
        "id": "EOT-_1UB0hy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_cell(c_t, h_t, x_t):\n",
        "  # Forget Gate\n",
        "  f_t = np.dot(W_fh, h_t) + np.dot(x_t, W_fx).T + b_f\n",
        "  f_out = sigmoid(f_t)\n",
        "  c_t = np.multiply(c_t, f_out)\n",
        "\n",
        "  # Input Gate\n",
        "  i_t = np.dot(W_ih, h_t) + np.dot(x_t, W_ix).T + b_i\n",
        "  i_out = sigmoid(i_t)\n",
        "  cand_t = np.dot(W_ch, h_t) + np.dot(x_t, W_cx).T + b_c\n",
        "  cand_out = np.multiply(i_out, np.tanh(cand_t))\n",
        "  c_t = np.add(c_t, cand_out)\n",
        "\n",
        "  # Output Gate\n",
        "  o_t = np.dot(W_oh, h_t) + np.dot(x_t, W_ox).T + b_o\n",
        "  o_out = sigmoid(o_t)\n",
        "  h_t = np.multiply(np.tanh(c_t), o_out)\n",
        "\n",
        "  return c_t.flatten(), h_t.flatten(), f_out.flatten(), i_out.flatten(), cand_out.flatten(), o_out.flatten()\n",
        "\n",
        "def LSTM_wrapper(num_rounds, data_index):\n",
        "  # Define Cell and Hidden states\n",
        "  c_t_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "  h_t_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "  f_out_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "  i_out_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "  cand_out_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "  o_out_mem = np.zeros([num_rounds + 1, hidden_size])\n",
        "\n",
        "  # Create -1st entry for memory lines\n",
        "  c_t_mem[0] = np.zeros(hidden_size)\n",
        "  h_t_mem[0] = np.zeros(hidden_size)\n",
        "  f_out_mem[0] = np.zeros(hidden_size)\n",
        "  i_out_mem[0] = np.zeros(hidden_size)\n",
        "  cand_out_mem[0] = np.zeros(hidden_size)\n",
        "  o_out_mem[0] = np.zeros(hidden_size)\n",
        "\n",
        "  actual_index = data_index * 10\n",
        "\n",
        "  for i in range(num_rounds):\n",
        "    c_t_cur = c_t_mem[i].reshape(hidden_size, 1)\n",
        "    h_t_cur = h_t_mem[i].reshape(hidden_size, 1)\n",
        "    f_out_cur = f_out_mem[i].reshape(hidden_size, 1)\n",
        "    i_out_cur = i_out_mem[i].reshape(hidden_size, 1)\n",
        "    cand_out_cur = cand_out_mem[i].reshape(hidden_size, 1)\n",
        "    o_out_cur = o_out_mem[i].reshape(hidden_size, 1)\n",
        "    c_t_mem[i + 1], h_t_mem[i + 1], f_out_mem[i + 1], i_out_mem[i + 1], cand_out_mem[i + 1], o_out_mem[i + 1] = LSTM_cell(c_t_cur, h_t_cur, get_features(actual_index + i))\n",
        "\n",
        "  return c_t_mem, h_t_mem, f_out_mem, i_out_mem, cand_out_mem, o_out_mem"
      ],
      "metadata": {
        "id": "FmthsIkZ0lZa"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Back Propagation Through Time (BPTT)"
      ],
      "metadata": {
        "id": "JuhUELU7SC4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bptt(res, x_t, i):\n",
        "  '''\n",
        "  res[0] -> c_t_mem\n",
        "  res[1] -> h_t_mem\n",
        "  res[2] -> f_out_mem\n",
        "  res[3] -> i_out_mem\n",
        "  res[4] -> cand_out_mem\n",
        "  res[5] -> o_out_mem\n",
        "  '''\n",
        "\n",
        "  # Constants\n",
        "  learningRate = 0.0001\n",
        "\n",
        "  # Find components of gradient\n",
        "  delta_b_f = (y - res[1][i]) * res[5][i] * (1 - np.tanh(res[0][i])) * res[0][i - 1] * res[2][i] * (1 - res[2][i])\n",
        "  delta_b_i = (y - res[1][i]) * res[5][i] * (1 - np.tanh(res[0][i])) * res[0][i - 1] * res[3][i] * (1 - res[3][i])\n",
        "  delta_b_c = (y - res[1][i]) * res[5][i] * (1 - np.tanh(res[0][i])) * res[0][i - 1] * res[4][i] * (1 - res[4][i])\n",
        "  delta_b_o = (y - res[1][i]) * np.tanh(res[0][i]) * res[5][i] * (1 - res[5][i])\n",
        "\n",
        "  b_f = delta_b_f\n",
        "  b_i = delta_b_i\n",
        "  b_c = delta_b_c\n",
        "  b_o = delta_b_o\n",
        "\n",
        "  # Update weights and biases based off of gradient calculation\n",
        "  w_fx -= learningRate * delta_b_f * x_t\n",
        "  w_ix -= learningRate * delta_b_i * x_t\n",
        "  w_cx -= learningRate * delta_b_c * x_t\n",
        "  w_ox -= learningRate * delta_b_o * x_t\n",
        "  w_oh -= learningRate * delta_b_f * res[1][i - 1]\n",
        "  w_fh -= learningRate * delta_b_i * res[1][i - 1]\n",
        "  w_ih -= learningRate * delta_b_c * res[1][i - 1]\n",
        "  w_ch -= learningRate * delta_b_o * res[1][i - 1]\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "GUgjuUqASLuN"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent"
      ],
      "metadata": {
        "id": "uNlxzsVIXleX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(10000):\n",
        "  for point in range(len(df)):\n",
        "    if point % 10 == 0:\n",
        "      res = LSTM_wrapper(10, point)\n",
        "      for i in reversed(range(10)):\n",
        "        bptt(res, get_features(point), i+1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "rCNIZeisXnMt",
        "outputId": "b4b9a98e-3479-4fc8-9bb4-2f7d495f46fb"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (2500,) (15,) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-68934781f2e6>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mbptt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-67-0cf3118e9b0c>\u001b[0m in \u001b[0;36mbptt\u001b[0;34m(res, x_t, i)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m   \u001b[0;31m# Find components of gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m   \u001b[0mdelta_b_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m   \u001b[0mdelta_b_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0mdelta_b_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2500,) (15,) "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validating the LSTM RNN"
      ],
      "metadata": {
        "id": "7IVjgMNsbpkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parse Music Data"
      ],
      "metadata": {
        "id": "VKKqIS8pbzAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import CSV File\n",
        "df = pd.read_csv(\"test_data.csv\")\n",
        "\n",
        "# Seperate columns into features\n",
        "chroma_mean = df[\"chroma_stft_mean\"].to_numpy()\n",
        "chroma_var = df[\"chroma_stft_var\"].to_numpy()\n",
        "rms_mean = df[\"rms_mean\"].to_numpy()\n",
        "rms_var = df[\"rms_var\"].to_numpy()\n",
        "scm = df[\"spectral_centroid_mean\"].to_numpy()\n",
        "scv = df[\"spectral_centroid_var\"].to_numpy()\n",
        "sbm = df[\"spectral_bandwidth_mean\"].to_numpy()\n",
        "sbv = df[\"spectral_bandwidth_var\"].to_numpy()\n",
        "\n",
        "# Convert label from string to int\n",
        "y = []\n",
        "for label in df['label']:\n",
        "  y.append(map.get(label))"
      ],
      "metadata": {
        "id": "7p3MG-xMbuC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize Music Data"
      ],
      "metadata": {
        "id": "C-dFa8tSb_wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = [chroma_mean, chroma_var, rms_mean, rms_var, scm, scv, sbm, sbv]\n",
        "\n",
        "# normalize between -1 and 1\n",
        "def normalize_range(arr):\n",
        "  arr_min = arr.min()\n",
        "  arr_max = arr.max()\n",
        "  for i in range(len(arr)):\n",
        "    arr[i] = (2 * (arr[i] - arr_min) / (arr_max - arr_min)) -1\n",
        "\n",
        "# normalize all data\n",
        "for x in features:\n",
        "  normalize_range(x)"
      ],
      "metadata": {
        "id": "AaIlLwvgcBaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collect expected outputs from RNN"
      ],
      "metadata": {
        "id": "_BBEF3qOcRxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(df)):\n",
        "  if point % 10 == 0:\n",
        "    res = LSTM_wrapper(10, point)\n",
        "    print(res)"
      ],
      "metadata": {
        "id": "Xry7ucH3cUu4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}